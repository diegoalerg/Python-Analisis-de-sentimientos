{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING TWEETS ['I love this car.', 'This view is amazing.', 'I feel great this morning', 'I am so excited about the concert', 'He is my best friend', 'I do not like this car', 'This view is horrible.', 'I feel tired this morning.', 'I am not looking forward to the concert.', 'He is my enemy.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "#Corpus de entrenamiento\n",
    "#tweets que se consideran de polaridad positiva\n",
    "\n",
    "pos_tweets = ['I love this car.', 'This view is amazing.', 'I feel great this morning', 'I am so excited about the concert', \n",
    "             'He is my best friend']\n",
    "\n",
    "#tweets que se consideran de polaridad negartiva\n",
    "\n",
    "neg_tweets = ['I do not like this car', 'This view is horrible.', 'I feel tired this morning.','I am not looking forward to the concert.',\n",
    "             'He is my enemy.']\n",
    "\n",
    "#Creamos los documentos de entrenamiento\n",
    "\n",
    "docs = pos_tweets + neg_tweets\n",
    "\n",
    "print('TRAINING TWEETS', docs)\n",
    "\n",
    "#Definimos el vectorizador. Las dimensiones del vector que representa una opinion son los valores de relavancia de \n",
    "#Las palabras de las opiniones. La metrica para calcular la relevancia es el tf. idf\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "        analyzer = 'word', #PUEDE TENER UNA FUNCION EN LA QUE DEFINO CUALES SON LOS DATOS QUE INTERESAN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "TRAINING MATRIX\n",
      "[[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0]\n",
      " [1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0]\n",
      " [0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.vocabulary)\n",
    "\n",
    "X = vectorizer.fit_transform(docs)\n",
    "\n",
    "print(\"TRAINING MATRIX\")\n",
    "X_train = X.toarray() #matriz con los vectores de entrenamiento\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA LABELS ['POS', 'POS', 'POS', 'POS', 'POS', 'NEG', 'NEG', 'NEG', 'NEG', 'NEG']\n",
      "TRAINING MATRIX\n",
      "[[0.         0.         0.         0.         0.59948298 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.7051983  0.         0.         0.         0.         0.\n",
      "  0.37857035 0.         0.         0.        ]\n",
      " [0.         0.         0.63912921 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.42261065 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.3431026  0.         0.         0.54331822]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.51416966 0.         0.\n",
      "  0.60484047 0.         0.         0.         0.         0.\n",
      "  0.         0.51416966 0.         0.         0.         0.\n",
      "  0.32469544 0.         0.         0.        ]\n",
      " [0.43988604 0.37394332 0.         0.         0.         0.37394332\n",
      "  0.         0.         0.43988604 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.43988604 0.37394332\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.50750737 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.50750737\n",
      "  0.         0.43142763 0.         0.3355785  0.         0.\n",
      "  0.         0.         0.43142763 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.43995454 0.\n",
      "  0.51753795 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.51753795 0.\n",
      "  0.         0.         0.         0.43995454 0.         0.\n",
      "  0.27782898 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.63912921 0.42261065 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.3431026  0.         0.         0.54331822]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.51416966 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.51416966 0.         0.         0.         0.\n",
      "  0.32469544 0.60484047 0.         0.        ]\n",
      " [0.         0.35025557 0.         0.         0.         0.35025557\n",
      "  0.         0.         0.         0.         0.41202109 0.\n",
      "  0.         0.         0.         0.         0.         0.41202109\n",
      "  0.         0.         0.         0.35025557 0.         0.35025557\n",
      "  0.         0.         0.41202109 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.58899657 0.         0.         0.         0.\n",
      "  0.         0.5007009  0.         0.3894615  0.         0.\n",
      "  0.         0.         0.5007009  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "        analyzer = 'word', #PUEDE TENER UNA FUNCION EN LA QUE DEFINO CUALES SON LOS DATOS QUE INTERESAN\n",
    ")\n",
    "\n",
    "#Entrenamiento\n",
    "\n",
    "data_labels = []\n",
    "\n",
    "for i in range(len(pos_tweets)):\n",
    "    data_labels.append('POS')           #Data Labelling\n",
    "\n",
    "for i in range(len(neg_tweets)):\n",
    "    data_labels.append('NEG')\n",
    "    \n",
    "print('TRAINING DATA LABELS', data_labels)\n",
    "\n",
    "X = vectorizer.fit_transform(docs)\n",
    "\n",
    "print(\"TRAINING MATRIX\")\n",
    "X_train = X.toarray() #matriz con los vectores de entrenamiento\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NEG' 'POS']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_train = data_labels\n",
    "import sklearn.svm\n",
    "\n",
    "classifier = sklearn.svm.LinearSVC() #definimos el clasificador\n",
    "#aplicar el algoritmo de svm a los datos de entrenamiento\n",
    "svm_model = classifier.fit(X=X_train, y=y_train) #donde x_train es la matriz con los vectores cada vector es una opinion\n",
    "                                                    #y_train son los outcomes las valoraciones\n",
    "\n",
    "new_opinions = ['This movie is horrible', 'The actor is wonderful and very handsome']\n",
    "\n",
    "#vectorizar las nuevas opiniones\n",
    "\n",
    "X1 = vectorizer.transform(new_opinions)\n",
    "\n",
    "#Predecir a  polaridad de las nuevas opiniones\n",
    "\n",
    "y_pred = svm_model.predict(X1)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
